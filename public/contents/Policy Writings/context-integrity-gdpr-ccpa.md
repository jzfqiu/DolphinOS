# Implications of Context Integrity on Data Privacy Regulations

*Jeff Qiu* 

The US is long due for a data privacy act. In the past decade, large-scale privacy violations by private companies such as Facebook have pushed many individuals into the debate about data privacy. Yet, with citizens, regulators, and companies [all supporting](https://www.wsj.com/articles/online-privacy-protections-gain-traction-with-lawmakers-tech-industry-11650978000) a federal data privacy law, the progress [has stalled](https://www.nytimes.com/wirecutter/blog/state-of-privacy-laws-in-us/) while the European Union and state legislatures hammer on with their own versions. The delay is expected given the tremendous challenges in crafting a data privacy regulation that fits the needs of the US market. Few precedences to such laws exist, and their effects on data privacy in practice are not well understood. With the help of a theoretical framework known as context integrity, this paper aims to examine the effectiveness of two recent data privacy laws, the General Data Protection Regulation (GDPR) and the California Consumer Privacy Act (CCPA). My analysis shows that the GDPR offers strong privacy protection by enabling a context-specific information flow as a default. However, its broad scope limits its adoption as a privacy norm. The CCPA provides a weaker set of protection but leaves the discussion open for conversations about norms that best satisfy the interest of individual users and data collectors.

## From Notice-and-Choice to Context Integrity

The necessity for privacy law in the US stems from the changing conception of data privacy. Although the US leads the world in internet-related technologies, the US conception of data privacy has traditionally been centered around businesses rather than users. In the past decade, new norms and frameworks surrounding data privacy warrant a regulation to protect users. Here I trace the evolution of data privacy as a concept to establish key elements that constitute an effective data privacy regulation.

The theoretical foundation of online privacy was built as far back as 1995 when legal scholar and privacy researcher Alan Westin proposed his influential taxonomy on online privacy. Funded mainly by private companies that have an interest in obtaining user data, [Westin&#39;s studies](https://www.cs.cmu.edu/~ponguru/CMU-ISRI-05-138.pdf) divide internet users in the US into three categories: the &quot;fundamentalists&quot; who place a high value on privacy, the &quot;pragmatists&quot; who are willing to sacrifice some privacy in exchange for services, and the &quot;unconcerned&quot; who are indifferent to privacy decisions. The pragmatists, Westin claimed, made up more than half of the US population. The broad categorization implies that most internet users make informed and calculated choices that lead them to give up their data to service providers, an assumption that companies capitalized on to camouflage their aggressive tracking mechanisms as non-privacy invasive.

Currently, the predominant framework of online privacy is the Notice-and-Choice model. Under the model, a service that collects users&#39; data informs users about its data collection process and asks users for their consent. In practice, these choices are rarely informed, let alone calculated. The lack of definition of proper notice has raised many privacy issues. [Studies and surveys](https://www.newamerica.org/oti/blog/how-notice-and-consent-fails-to-protect-our-privacy/) have pointed out that the framework often fails to communicate key privacy issues to users. First, the information about data collection is usually displayed in lengthy legal documents that take an unreasonable effort for an average user to understand. Even if the user can read through the documents, not all services record their data practices adequately. Some even deliberately left out information that would discourage users from surrendering their data. Finally, in the rare cases where users are able to weigh the costs of the data collection process to their privacy, their choices are often limited to accepting the terms in their entirety or being denied all services.

Scholars have attempted to address the imbalance between users and data collectors and have developed alternative frameworks to approach digital privacy. One of the more developed frameworks is [Helen Nissenbaum&#39;s contextual integrity](https://www.amacad.org/publication/contextual-approach-privacy-online), which observes the flow of data under its context â€“ the sender, the receiver, the subject of the data, the type of information, and the condition under which the flow takes place. Theses information helps clarify the context, which allows observers to determine if the flow has violated the privacy norm specified for that context. The divorce of the data and its context also aims to compare the user&#39;s expectation of privacy in non-digital settings. For example, users&#39; interactions on social media should be compared against social interactions in real life rather than against other conventional data collection practices.

While not directly used as a legal tool, the framework helps evaluate the quality of privacy protection regulations. The framework implicates three critical aspects of an effective privacy protection regime. First, a standard for deconstructing the data flow is crucial in discovering privacy violations in a complex network of personal data exchanges. [A 2019 study](https://www.ftc.gov/system/files/documents/public_events/1415032/privacycon2019_yan_shvartzshnaider.pdf) used the data flow model in context integrity to expose numerous loopholes in Facebook&#39;s privacy notice. Without a structured approach, attempts to clarify data usage risk omission of essential details that may significantly impact the user&#39;s decision-making process. Focusing on data flow could help regulators develop more detailed and practical requirements for data practice disclosure.

Second, developing privacy norms for users and businesses is more effective than imposing costly regulations. User&#39;s privacy expectations are context-specific and hard to capture, and regulators may approach the privacy problem more effectively by focusing on mandating a basic level of data privacy and leading public discourse toward a more defined standard for privacy. From the perspective of privacy regulations, the implication suggests that rules should aim to refine the communication between businesses and users while gradually pushing the boundaries between legal collection and privacy violation in response to public reactions.

Finally, drawing a parallel between users&#39; offline and online activities means that adequate privacy protection may inevitably erode some benefits that digitalization offers. Online services are naturally more suited for gathering and sharing user data than their offline counterparts. To match the user&#39;s privacy expectation of online activity with an offline one, regulations inevitably need to raise the cost of data collection or data breach. Therefore, one of the regulator&#39;s responsibilities is to gauge the trade-off between privacy and the cost to businesses benefiting from the data economy.

## The GDPR

Adopted in 2016, the GDPR is perhaps the most influential data privacy law in the past decade. On the one hand, regulators hail its stringent protection of user&#39;s data as &quot;[the toughest privacy and security law in the world](https://gdpr.eu/tag/gdpr/)&quot;. On the other hand, critics point out the regulation&#39;s [low adoption rate beyond the EU&#39;s border](https://legal.thomsonreuters.com/en/insights/articles/top-five-concerns-gdpr-compliance), [vague technical requirements](https://legal.thomsonreuters.com/en/insights/articles/top-five-concerns-gdpr-compliance), and [lack of enforcement in EU member states](https://techcrunch.com/2020/06/24/gdprs-two-year-review-flags-lack-of-vigorous-enforcement/) as signs of weakness. I argue that the GDPR has managed to avoid many historical pitfalls in privacy regulation, although its early lack of enforcement suggests that its strong privacy protection could be resource-intensive for regulators and costly for businesses.

Although the collection of additional data procedures still largely relies on the user&#39;s informed consent, the GDPR has attempted to alleviate the burden on the user by simplifying the information needed to make the decision. [Article 14](https://eur-lex.europa.eu/legal-content/EN/TXT/HTML/?uri=CELEX:32016R0679&amp;from=EN#d1e2355-1-1) lists six pieces of information that collectors need to present to users before asking for consent, including the purpose of collection, the identity of the data recipient, and the user&#39;s right to control the data collected. Together, these attributes construct a clear picture of the data flow and ensure users have access to digestible information regarding the data collection process. For more concerned users, [article 12](https://eur-lex.europa.eu/legal-content/EN/TXT/HTML/?uri=CELEX:32016R0679&amp;from=EN#d1e2182-1-1) requires that data collectors provide details of data collection spread out in 11 different articles in &quot;concise, transparent, intelligible and easily accessible forms&quot; to the users. Focusing on accessibility, these measures are significant improvements from the era where users are forced to read endless pages of unstructured legal jargon, effectively shrinking the information gap between users and data collectors.

The GDPR takes a step further by introducing clauses related to data minimization and privacy by default. [Article 25](https://eur-lex.europa.eu/legal-content/EN/TXT/HTML/?uri=CELEX:32016R0679&amp;from=EN#d1e3063-1-1) states that without user intervention, personal data should only be collected when they are &quot;necessary for each specific purpose of the processing&quot; and not be made available to an &quot;indefinite number of natural persons&quot;. Under the contextual integrity framework, the first part governs the condition through which the data flow happens, while the second part constraint user data to the designated recipients of the data. Combined with [article 30](https://eur-lex.europa.eu/legal-content/EN/TXT/HTML/?uri=CELEX:32016R0679&amp;from=EN#d1e3265-1-1), which requires companies to record this information and report them to regulatory agencies, these regulations construct a clear picture of data flow that imposes a basic level of accountability on the data collection process, even for users making uneducated choices.

While it excels at improving the protection of users, the GDPR raised concerns over its lack of enforcement. In a 2020 [report](https://brave.com/static-assets/files/Brave-2020-DPA-Report.pdf) titled &quot;European Governments are Failing the GDPR&quot;, privacy-centered browser vendor Brave accused governments across Europe of underfunding and under-staffing agencies responsible for enforcing the GDPR, the Data Protection Agencies. The report cited Ireland&#39;s accelerating number of GDPR complaints against its decelerating buildup of funds and budgets, advocating for EU-wide action against the Ireland government for failing to scrutinize big tech companies located in its territory. While enforcement across Europe has picked up pace as DPAs began to levy [heavier fines](https://www.tessian.com/blog/biggest-gdpr-fines-2020/) on companies in the last two years, constraints on government resources remain a challenge.

In addition, GDPR compliance has been slow and costly for smaller businesses, leading to questions about its impact on a competitive market environment. In a [2019 survey](https://gdpr.eu/wp-content/uploads/2019/05/2019-GDPR.EU-Small-Business-Survey.pdf), more than half of small business owners failed to recognize critical components in GDPR or were unsure about their business&#39;s compliance status, despite having invested heavily in GDPR compliance and stating their support for better data privacy. Respondents in the survey hope their small size would help them evade penalties from regulators, but most are not confident that they have the financial and legal resources to fight fines. These responses show that small businesses are sometimes forced to choose between competitiveness and compliance, which is not a problem that well-funded multi-national corporations like Google face. While selective enforcement from regulators avoids the question of whether the GDPR hurts competition, the concerns from small business owners suggest that the privacy norm is a long-term project that requires gradual increment. Pushing forward a radically different norm from existing implementation leads to gaps that regulators and small market players would struggle to fill.

## The CCPA

Despite its drawbacks, the GDPR remains a powerful influence in discussions about online privacy. It inspired several legislations outside the EU, including California&#39;s state-level data privacy regulation, the [CCPA](https://oag.ca.gov/privacy/ccpa). While the two laws overlap in a few essential areas of privacy protections, the CCPA is more limited in the scope of protection and enforcement.

The CCPA is similar to the GDPR in the rights they grant to users, yet it falls short in the lack of a prior consent mechanism and limitation on default collection. Similar to [articles 15-18](https://gdpr-info.eu/art-18-gdpr/) of GDPR, [section 105 and 106](https://leginfo.legislature.ca.gov/faces/codes_displayText.xhtml?division=3.&amp;part=4.&amp;lawCode=CIV&amp;title=1.81.5.) of the CCPA grants users the right to access, modify, and delete their personal information. In addition, [section 110](https://leginfo.legislature.ca.gov/faces/codes_displaySection.xhtml?lawCode=CIV&amp;sectionNum=1798.110.) of the CCPA requires businesses to disclose the context of data collected, including the same sets of information necessary to construct an informative data flow model. However, while [section 120 and 121](https://leginfo.legislature.ca.gov/faces/codes_displayText.xhtml?division=3.&amp;part=4.&amp;lawCode=CIV&amp;title=1.81.5.) grants the users the right to opt-out of data collection outside the purpose of providing necessary service, they do not require businesses to obtain consent before the collection occurs. The lack of privacy default makes the privacy protection in the CCPA much weaker than GDPR, allowing possible privacy-violating collections to occur inconspicuously. Nonetheless, the structured requirement for disclosure is still an improvement from the existing notice-and-choice system.

The CCPA also differs from the GDPR in enforcement, granting fewer resources for prosecution and milder punishment for non-compliance. [Section 155](https://leginfo.legislature.ca.gov/faces/codes_displaySection.xhtml?lawCode=CIV&amp;sectionNum=1798.155.) of the CCPA gives the power to prosecute violators to the state attorney general, to whom CCPA violation is just one of the many responsibilities. In 2019, GDPR-chartered DPAs around Europe received [more than 140,000 complaints](https://ec.europa.eu/info/sites/default/files/infographic-gdpr_in_numbers.pdf), which the agencies struggled to process. The state attorney general, processing [less than 10,000 cases](https://www.justice.gov/usao/page/file/1476856/download) annually, is likely unable to go after most privacy violations. This shortcoming, however, is being addressed in the upcoming update in the [California Privacy Rights Act (CPRA)](https://vig.cdn.sos.ca.gov/2020/general/pdf/topl-prop24.pdf), which builds on the CCPA to establish a Privacy Protection Agency to enforce the CCPA. Furthermore, the section mandate that violators could be fined no more than $7500, which is trivial compared to the millions of dollars fined by GDPR violations. Together, violating the CCPA will incur only a nominal cost, making the privacy safeguards in the regulation more akin to recommendations than regulations.

Finally, the CCPA applies to a smaller number of businesses. While the GDPR applies to all entities that process user data, including NGOs and government agencies, [Section 140](https://leginfo.legislature.ca.gov/faces/codes_displaySection.xhtml?sectionNum=1798.140.&amp;nodeTreePath=8.4.47&amp;lawCode=CIV) of the CCPA limits application to businesses that satisfy one of the three criteria: exceeding $25 million in annual revenue, collecting more the personal information of more than 50,000 individuals, or deriving more than half of their annual revenue from selling personal data. These requirements are likely designed to exempt small businesses from the compliance cost. Although CCPA&#39;s compliance costs are expected to be lower than those in the GDPR due to laxer privacy requirements and lower cost of violation, such carveout is meaningful to startups and small businesses that lack the additional resource dedicated to privacy protections.

As one of the five data privacy laws currently in effect in the US, the CCPA is a significant step forward in data privacy in a political environment dedicated to deregulation and free enterprise. While many criticize its weak privacy protection compared to the GDPR, privacy measures laid out in the CCPA are easier to implement, and as the introduction of the CRPA demonstrates, future additions to the law could improve its privacy protection while encouraging discussions regarding new possible directions on privacy norms in non-government sectors.

## Beyond Regulations: Private Sector Initiatives

For the US tech industry that saw a sizable portion of revenue coming from user data, the heat of the GDPR and CCPA may not have an immediate negative impact on their business model, but it is enough to accelerate the privacy innovations that originated from their user&#39;s demand for better privacy. Much of the recent technical efforts from companies focus on decreasing third-party tracking. Firefox, for example, began what was branded as the &quot;cookie apocalypse&quot; by disabling third-party tracking cookies in an [update](https://blog.mozilla.org/security/2021/02/23/total-cookie-protection/) in 2021. Google soon followed suit, first with the controversial scheme of [Federated Learning of Cohorts](https://github.com/WICG/floc), then with a more complex system of measures collectively known as the [Privacy Sandbox](https://privacysandbox.com/intl/en_us/). These regimes attempt to limit third-party access to users&#39; data flow generated on their platforms, aligning with regulators&#39; concern over the uncontrolled sharing of user data. With its unique position as a hardware and operating system producer, Apple took a step further and began to limit first-party access on its platforms. Introduced in the same year, the [App Tracking Transparency](https://developer.apple.com/documentation/apptrackingtransparency) program applies GDPR&#39;s opt-in policy and forces apps running on Apple devices to obtain users&#39; consent before accessing certain categories of data. The move has antagonized companies that rely on user data for their revenue, most notably Facebook, which [admits](https://www.wsj.com/articles/facebook-meets-apple-in-clash-of-the-tech-titanswe-need-to-inflict-pain-11613192406) that the program damages its revenue model and vows to fight back.

These gestures suggest that privacy consensus among regulators, companies, and users is converging. Nonetheless, a data privacy law is still instrumental in the debate on data privacy by providing the conceptual foundation for companies and users to build upon, in addition to the statutory protections it offers. As the [flurry of privacy bills](https://iapp.org/news/a/privacy-bills-in-the-117th-congress/) in the current congress shows, lawmakers are aware of the need for privacy law. How much would the final product address the shortcomings of existing laws, however, remains to be seen.